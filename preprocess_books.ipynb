{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8898041it [03:02, 48779.59it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import json \n",
    "from tqdm import tqdm\n",
    "\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in tqdm(parse(path)):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df = getDF('../data/source_data/reviews_Books_5.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A10000012B7CGYKOMPQ4L</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>Adam</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Spiritually and mentally inspiring! A book tha...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Wonderful!</td>\n",
       "      <td>1355616000</td>\n",
       "      <td>12 16, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2S166WSCFIFP5</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>adead_poet@hotmail.com \"adead_poet@hotmail.com\"</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>This is one my must have books. It is a master...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>close to god</td>\n",
       "      <td>1071100800</td>\n",
       "      <td>12 11, 2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1BM81XB4QHOA3</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>Ahoro Blethends \"Seriously\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This book provides a reflection that you can a...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Must Read for Life Afficianados</td>\n",
       "      <td>1390003200</td>\n",
       "      <td>01 18, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1MOSTXNIO5MPJ</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>Alan Krug</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I first read THE PROPHET in college back in th...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Timeless for every good and bad time in your l...</td>\n",
       "      <td>1317081600</td>\n",
       "      <td>09 27, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2XQ5LZHTD4AFT</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>Alaturka</td>\n",
       "      <td>[7, 9]</td>\n",
       "      <td>A timeless classic.  It is a very demanding an...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A Modern Rumi</td>\n",
       "      <td>1033948800</td>\n",
       "      <td>10 7, 2002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              reviewerID        asin  \\\n",
       "0  A10000012B7CGYKOMPQ4L  000100039X   \n",
       "1         A2S166WSCFIFP5  000100039X   \n",
       "2         A1BM81XB4QHOA3  000100039X   \n",
       "3         A1MOSTXNIO5MPJ  000100039X   \n",
       "4         A2XQ5LZHTD4AFT  000100039X   \n",
       "\n",
       "                                      reviewerName helpful  \\\n",
       "0                                             Adam  [0, 0]   \n",
       "1  adead_poet@hotmail.com \"adead_poet@hotmail.com\"  [0, 2]   \n",
       "2                      Ahoro Blethends \"Seriously\"  [0, 0]   \n",
       "3                                        Alan Krug  [0, 0]   \n",
       "4                                         Alaturka  [7, 9]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  Spiritually and mentally inspiring! A book tha...      5.0   \n",
       "1  This is one my must have books. It is a master...      5.0   \n",
       "2  This book provides a reflection that you can a...      5.0   \n",
       "3  I first read THE PROPHET in college back in th...      5.0   \n",
       "4  A timeless classic.  It is a very demanding an...      5.0   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0                                         Wonderful!      1355616000   \n",
       "1                                       close to god      1071100800   \n",
       "2                    Must Read for Life Afficianados      1390003200   \n",
       "3  Timeless for every good and bad time in your l...      1317081600   \n",
       "4                                      A Modern Rumi      1033948800   \n",
       "\n",
       "    reviewTime  \n",
       "0  12 16, 2012  \n",
       "1  12 11, 2003  \n",
       "2  01 18, 2014  \n",
       "3  09 27, 2011  \n",
       "4   10 7, 2002  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df \n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8898041/8898041 [13:06<00:00, 11314.27it/s]\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for i in tqdm(range(len(df_new))):\n",
    "    if df_new.iloc[i]['unixReviewTime'] < 1388505600 :\n",
    "        continue\n",
    "    tmp = {}\n",
    "    tmp[\"user\"] = df_new.iloc[i][\"reviewerID\"]\n",
    "    tmp[\"item\"] = df_new.iloc[i][\"asin\"]\n",
    "    tmp[\"rating\"] = df_new.iloc[i][\"overall\"]\n",
    "    tmp[\"ReviewTime\"] = df_new.iloc[i][\"unixReviewTime\"]\n",
    "    tmp[\"reviewText\"] = df_new.iloc[i][\"reviewText\"]\n",
    "    \n",
    "    res.append(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1974115\n"
     ]
    }
   ],
   "source": [
    "print(len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2370585/2370585 [02:23<00:00, 16521.81it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "import json \n",
    "asin_2_title = {}\n",
    "with open(\"../data/source_data/meta_Books.json\", 'r') as f:\n",
    "    datas = f.readlines()\n",
    "for data in tqdm(datas):\n",
    "    data = data.strip()\n",
    "    data = eval(data)\n",
    "    asin_2_title[data[\"asin\"]] = data.get(\"title\",None) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1974115/1974115 [00:01<00:00, 1048824.91it/s]\n"
     ]
    }
   ],
   "source": [
    "for data in tqdm(res) :\n",
    "    data[\"title\"] = asin_2_title[data[\"item\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user': 'A1BM81XB4QHOA3',\n",
       " 'item': '000100039X',\n",
       " 'rating': 5.0,\n",
       " 'ReviewTime': 1390003200,\n",
       " 'reviewText': 'This book provides a reflection that you can apply to your own life.And, a way for you to try and assess whether you are truly doing the right thing and making the most of your short time on this plane.',\n",
       " 'title': 'The Prophet'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1974115/1974115 [00:02<00:00, 863815.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before filter total users:  352910\n",
      "before filter total items:  236524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_count = {}  # 每个用户购买过多少商品\n",
    "item_count = {}  # 每个商品被多少用户购买\n",
    "for data in tqdm(res):\n",
    "    user = data[\"user\"]\n",
    "    item = data[\"item\"]\n",
    "    if data[\"ReviewTime\"] > 1388505600:\n",
    "        user_count[user] = user_count.get(user,0) + 1\n",
    "        item_count[item] = item_count.get(item,0) + 1\n",
    "print(\"before filter total users: \", len(user_count))\n",
    "print(\"before filter total items: \", len(item_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1397554\n",
      "1974115\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for data in res:\n",
    "    if data[\"user\"] and data[\"item\"] and data[\"rating\"] and data[\"ReviewTime\"] and data[\"reviewText\"] and data[\"title\"]:\n",
    "        count +=1\n",
    "print(count)\n",
    "print(len(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter items and users interactions less 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1974115 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1974115/1974115 [00:01<00:00, 1525383.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after filtered items total datas:  1011194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1011194/1011194 [00:00<00:00, 1650067.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after filter users totla datas:  284980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284980/284980 [00:00<00:00, 1214843.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total user:  14057\n",
      "total items:  25082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284980/284980 [00:00<00:00, 892836.39it/s]\n",
      "100%|██████████| 284980/284980 [00:01<00:00, 270459.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 32, 140, 151, 267, 369, 795, 1641, 1727, 1734, 1812, 2072, 2109, 2146, 2309, 2637, 3324, 6505, 7583, 7584, 8702, 10834, 12459, 12678, 13597, 13610, 14750, 16813, 18813]\n",
      "['The Prophet', 'Perelandra (Cosmic Trilogy)', 'To Kill a Mockingbird', 'The Lion, the Witch, and the Wardrobe (Chronicles of Narnia)', 'The Abolition of Man', 'Catch-22 CD', 'The Curriculum: Everything You Need to Know to Be a Master of Business Arts', 'All Quiet on the Western Front', 'The 48 Laws of Power', \"Cat's Cradle (Essential Penguin)\", 'Atlas Shrugged', 'Mastery', 'Think and Grow Rich', 'The Four Loves', 'The Audacity of Hope: Thoughts on Reclaiming the American Dream', \"The Lean Startup: How Today's Entrepreneurs Use Continuous Innovation to Create Radically Successful Businesses\", \"Ender's Shadow (The Shadow Series)\", 'Delivering Happiness: A Path to Profits, Passion, and Purpose', 'A Brief History of Time: And Other Essays', 'Greatest Salesman In the World', 'What to Say When you Talk To Yourself', 'Centered Leadership: Leading with Purpose, Clarity, and Impact', 'Built to Sell: Turn Your Business Into One You Can Sell', 'Go Pro: 7 Steps to Becoming a Network Marketing Professional', 'Lead Positive: What Highly Effective Leaders See, Say, and Do', 'Startup Leadership: How Savvy Entrepreneurs Turn Their Ideas Into Successful Enterprises', 'Big Data at Work: Dispelling the Myths, Uncovering the Opportunities', 'A Short Guide to a Long Life', 'Choose Yourself!']\n",
      "[5.0, 4.0, 5.0, 5.0, 3.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 4.0, 5.0, 5.0, 4.0, 5.0, 4.0, 4.0, 5.0, 5.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 5.0]\n",
      "[\"Echoing the reviews of others - it is obvious that Gibran both was inspired by and inspired many of the great writers of all ages.  From Buddha to Coehlo, and countless others in between, there is a depth of truth and a veil of simplicity that, once lifted, opens the mind, heart and soul to universal wisdom.It is not hard to understand why Gibran was as popular in his day, and in the 1960's, as he was.  Covering the landscape from religion to love, Gibran bubbles up deep truths in the form of a farewell speech from the Prophet to the people of his city before he sets sail on a final journey.  The metaphors are numerous and the scale of depth is exceptional.The book itself is nearly 100 pages, but the content is not readable at any level rapidly.  This book is one that bears constant revival and renewal.  It's a well that provides the reader with sweet water of wisdom which merits frequent draws to slake the thirst.A must have and a must read.\", 'Enough exposure to CS Lewis will bring any reader to the realization that there is much more there than meets the eye. This second book in his sci fi trilogy tackles the beginnings of &#34;humanity&#34; on Venus, and the salvific role played by trilogy protagonist Dr. Ransom. As science fiction goes, the book is OK. As an allegory of the fall of Eden and the avoidance of original sin, it is very well done. Combine the two for a very readable but not amazingly remarkable novel.', \"I never read this as a young man, and don't know if I would have fully appreciated it if I had.  So, even if you read this in high school or college, it has a depth of meaning and element of profundity that is amplified as an adult - especially an adult with children.  You begin to better understand the struggles faced by Atticus Finch, the wonderment and wisdom of Scout and the coming of age of Jem - all with eyes that have seen this in your life experience.  The prejudices of the community are abhorrent to the modern educated reader - and yet were the norm within a generation of our adulthood - and have not yet been fully eradicated.It is a powerful book, with amazing insights and a colloquial feel that really engages the modern reader.  A MUST read.\", \"Rereading this after nearly 30 years brings a whole different perspective on the book.  Even after seeing the movie, the elements of symbolism and allegory bring Lewis' own Christology alive through this fantasy retelling. Even discounting the Christian overtones, the book is a masterfully written piece of magical fantasy that will engage the 13 year old - as it did for me 30 years ago - as well as the 43 year old rereading it today.  An absolute must read.\", 'I read this after devouring many other works by Lewis - including his philosophically oriented &#34;Four Loves&#34;.  In comparison to his masterful fiction and eminately readable Christian apologetics, this falls short of the mark.  Discussing the Tao of life, I struggled to make heads or tails of the premise.  Lewis explores the commonalities across some major world religions and provides an ethical philosophy that is tough to digest.', \"Catch-22 is a slow burn, not a fast moving page turner.  The premise of absurdist comedy and dark humor guides the reader through the moral chasms of bureaucracy, war, command, politics and self-interest in this deep and well written classic.  As noted by many of the other reviewers who did not give the book 5 stars, the book was written for a time and a culture that has changed in 60 years.  So, while the human nature and the brilliance of the writing - as well as the depth of meaning - remain, the modern reader will find the book a bit of a slow go.  Additionally, the writing style was emergent and edgy in the 1950's became more mainstream with the likes of the Twilight Zone, Stephen King, M*A*SH* and other books, movies and stories that take some of the complete stylistic shock out of the read.The book is one of the defining reads of the 20th Century, and explores humanity in a creative and darkly humorous way.  Worth picking up, and probably still deserves a place on a must read list.\", 'After 20 years in the business world - in positions ranging from bank teller to CEO, I can assure the reader that Stanley Bing captured the cynical realism of the business world in this book.  A biting and humorous look at the skills necessary to make it in business, Bing brings a sardonic wit to power struggles, office politics, strategic planning and office romance.Not quite sure what to expect at the beginning, the book takes the reader through a &#34;course&#34; that includes 100, 200 and 300 level &#34;courses&#34; on :How not to Look Stupid&#34; and &#34;Crisis Management&#34;, while presenting faux statistics and graphs that are, unfortunately, directionally correct even in their absurdity.  Elements of the book have been lived by anyone who worked in an office environment, and the book may very well be the best literary complement to the movie &#34;Office Space&#34; yet devised.I would classify the book as being a fun and engaging read - but a bit long and it bogs down in spots.  You really need to have worked in an office to get the humor and sarcasm - and they are there in spades.  As noted, this is absolutely NOT a MBA in a book.  Rather, it is the anti-MBA, and valuable for a laugh or some perspective.', \"12 years a soldier, and I never read this book until long after I was out.  And that was probably a blessing in one sense.  Remarque brings the horror of war alive in this page turning and gripping story of Paul Baumer's experience in World War I.  Starting with the fallacy of patriotism to a idealistic view of humanity in the middle of the book, to a deep despair and death at the end, Remarque plays on every emotion from joy to sadness, fear to heroism, and love and hate.  At times, you can seemingly smell the mud and the stench of war - see the lack of humanity and the distancing of feeling in the first person narration - and the end demonstrates the complete insignificance of the individual to the collective and the complete significance of the individual to each other.  The contrast between the death of Kat and the end of the book stands as tribute to the dehumanizing elements of war.A must read, and a must feel experience.\", 'The 48 laws of power may not be nice, they may not be what you aspire to, and they may not be the world in which you wish to live.  Unfortunately, Robert Greene has nailed down 48 truisms that need to be understood by anyone responsible for managing, leading, selling, cajoling or subjected to any of those things.Greene takes the best and worst of human psychology and masterfully integrates lessons from history, quotations from classical literature and an entertaining if somewhat pedantic writing style to make the reader alert to the approach.  Reminding this reviewer of the tone taken by Machiavelli in &#34;The Prince&#34;, Greene aims to both instruct and entertain while not passing moral judgement on the contents.Learn the 48 laws.  Understand that they are derivative of our nature, sociology and psychology, and accept that the information in the book is useful - if at times unpleasant to comprehend.', \"Vonnegut takes the reader to the edges of the absurd with this post-apocalyptic story of the limits of science and society.  In a story launched through the desire to understand the man behind the first nuclear bomb, the author - Jonah - finds himself intertwined with one of the most dysfunctional families in the Honekkers - a family unique in both their ability to unleash the destructive elements of science and their inability to understand the implications of their actions.Coupled with the destructive elements of pure science as embodied by the multifaceted Honekker family are other archetypes such as Bokonon - the creator of a cynical religion known as Bokononism, which begins with telling all believers that it is a grand lie - and then seeing almost universal adherence among the people of San Lorenzo.  The religion serves as an escape and polarizing force for both the government and the people to provide a basis of happiness and distraction from the object poverty of their lives - similar to Marx's opiate of the people.The depth of symbolism and social commentary contained in Cat's Cradle is exceptional - and is nearly impossible to describe adequately in a review.  It was a page turner in the sense that the storyline was well done in the absurd.  It was difficult to turn the page, however, as each word is loaded with meaning that triggers thought and exploration.  This was my first Vonnegut novel, and will not be the last.  A great read.\", \"Yes, it is 1100 pages of microscopic type. Yes, There are a few monologues that are 20 pages long.  However, if you are concerned about the length of the books or the speeches, this book probably isn't going to be your cup of tea, anyway.Rand writes of an apocalypse of the modern world - caused by the withdrawal of the &#34;human mind&#34; - the best, the brightest, the creative...  The plot summary is lengthy and can be found in many other reviews. The meat of the book is in the philosophy.  Like the character Gordon Gekko 30 years later - Rand espouses the value that &#34;Greed is Good&#34;.  But it isn't greed qua greed she writes about.  It is the ability of the exceptional to excel, while the jealousy of those who benefit from the creativity of the excellent drive a siren's cry for equality and control.Rand takes the premise to a level of the absurd - and yet, the 2008 financial crisis, the recent call for centralized planning in healthcare and other government functions are eerily similar to the scenarios laid out in Atlas Shrugged.  The cry for revenge on the evil capitalists who profited at the expense of the 'common man' ring as loud today as they did 50 years ago in this book.There are powerful messages and thoughts in the book that, if read objectively, will cause any reader of any philosophy or political persuasion to think critically about motivations, roles and results.  While Rand's extremes in both length and philosophy may drive the average reader away - the person she wrote this book for is not the average reader anyway.  It is worth the time, the effort and the thought.\", \"If you are looking for an insight into how you can significantly improve yourself and your abilities, this book will provide it.  Generally well written (though repetitive in places), Greene describes the process by which one becomes a master in their chosen craft.  The biggest element missing from the book was really the ability or meaningful and useful guidance on HOW to choose that path or craft initially.  If you know your craft and life's work, then the remaining 400 pages are amazingly useful.  However, some of us struggle with how you find that focus and direction to begin to master, and in that aspect of Mastery, the book falls short.  This is a very good book, and by all means should be read by anyone looking to master a craft, trade, skill or process.  However, if you are uncertain WHAT to master, the book will prove to be short of the mark.\", 'As noted by several other reviewers, the 1937 edition is available for free online, and there have been more than a few reprints and editions, so to some extent - caveat emptor.  Having started with that caveat, &#34;Think & Grow Rich&#34; is one of the original books of its type by one of the original 20th Century self-help authors.  Napoleon Hill himself led an interesting and somewhat unexpected life (read his bio online), and the book proved to be both his beneficiary and his bane.The 13 principles of success it contains, however, and the solid information it provides are as valuable today as they were 75 years ago.  Focus, the need for a mastermind group, and most of all - following the Golden Rule to achieve success - resonate strongly as fundamental tenets of psychology, leadership and success.I first read an earlier edition of this book 20 years ago, and periodically pick up a copy or an audiobook of it every few years.  It is good enough and fundamental enough that I keep coming back - and given the amount of books I read, to keep coming back to a favorite says something.', 'C.S. Lewis brings theology, philosophy and plain old homespun wisdom alive in this profound book on the 4 loves.  Beginning with an introduction to love and the purpose of love, Lewis then takes the reader on an expose on the four loves of:*Affection*Friendship*Eros*CharityThe entire book is not only profound in basis and thought, but Lewis brings a sense of humor and levity to what could be (and sometimes is in the book) a very weighty subject.  Writing from a Christian perspective, Lewis ends up tying all love back to divinity through comparison and contrasting.A great book. Well worth the few hours it will take to get through for the first time.  It may end up a treasured part of your collection.', 'I had a chance to listen to the audiobook version, as read by then Senator Obama.  I will state that the 4 CD set was well narrated, and I was pleasantly surprised by the moderate tone, the pragmatic approach and the bipartisan and thoughtful approaches advocated by the senator. The content comes across as practical, moderate, well articulated and oftentimes thought provoking.  It is a good book for any politician or person interested in politics to listen to, as it recalls the hope of 2008 and the promise of true centrist leadership.Whether the job changed the man, or the positions in the book were designed more for getting elected than governing is up to the reader to decide.  It is worth the time to listen to or read, however.', 'I will start the review by saying that I am the President of a small/mid sized technology based company (100 employees) - with about 20 years of management experience and a lot of business school as well as a Lean Six Sigma black belt.  The fact that this rated five stars for me is an indicator that, unlike some of the other reviewers, I believe that this is not only a valuable read,but a beautiful melding of lean principles with practical business start up information at a level that anyone contemplating entrepreneurship should grasp.I found the concept of applying lean principles to the start up world ingenious.  We are an agile (scrum) shop, and the drumbeat has been fewer, faster, focused, fail fast and engage the customer early and often.  While many of the agile methodologies espouse lean principles implicitly (and in some cases explicitly), many of those resources are geared to project management.  This book transcends the business as a product - and the start up as the project.  The application of lean and agile principles to the day to day management of the business works - and is compelling.If you are contemplating a role in a start up - or even as a manager/intrapreneur in a larger organization, the principles and insights found in this book will be invaluable and easily understandable - especially to the agile practitioner.  A must have resource for the technologist entrepreneur - or candidly any manager in any type company.  The book is that transcendent.', \"Having read many of the reviews posted here, I tend to agree that this book is best read after the original Ender's Game and that the parallels are imperfect and the desire of the author to inflate the importance of Bean in this second series is probably not completely aligned to the original work.  That does not diminish the exceptional writing, the story line, or the emotional elements that appear in the book.  Not quite as amazing as the original - and with a rather slow start to the story - the finish of Ender's Shadow is both touching and entertaining.  The plot twists are somewhat predictable in hindsight, but serve the purpose to keep the pages turning.  The author seems to work hard to integrate some of the childhood antagonists and does so in a somewhat clunky and contrived manner.  However, the book is worth the read - especially if you enjoyed the first one.\", \"The book is a good, and easy read.  Tony Hsieh takes the reader on a light hearted, and easy to read, whirlwind tour of his childhood through the sale of Zappos to Amazon...and beyond.  As noted by many other reviewers, the book is extremely entertaining, but focuses more on the lifestyle and Tony's experience than replicable business elements that might be expected given the title.The Zappos culture is incredible, but Tony takes too little time explaining it, and the steps taken and lessons learned in developing it.  I was hoping for more lessons learned and accidents avoided from his initial experience at LinkExhange that helped avoid the same challenges at Zappos - and this was only lightly covered.Having said that, the real gems of the book are the last chapter and the epilogue.This is the 20 page meat and potatoes that Hsieh alludes to in the other 200 pages of the book.  The driving force of happiness, purpose and connection. Ultimately, I judge a business book by how much it makes me think or change my perspective.  This one didn't until the last 20 pages - which almost transformed a 3 star review into a 5 star.\", \"Reading the book reminded me of a science class with your favorite professor.  During the lecture and lab, it seemed so logical, and so elementary that you wondered why science was so hard - and then the application of the scientific method to prove the lectures remind you of what an amazing scientist it is that can make the extraordinarily complex seem understandable.  Hawking accomplishes this masterfully in this must read book on the history of our universe.  Time, space, string theory, multiple dimensions are all brought to life in an easy to read (if not fully understand) way.  Augmented with plenty of illustrations and no equations, this approach to science is available to anyone - and Hawking's masterful writing style is a true gift.  A must read.\", \"Og Mandino's own story is an amazing transformation of a man from failure to success.  This, his best known work, will take the reader through a series of steps that, if followed, will transform the mind.  A series of &#34;scrolls&#34;, revealed as part of an overarching story, will transform the reader into a positive thinking, positive acting person.  This book isn't just for sales people, it is for everyone.  The focus of the  &#34;scrolls&#34; are:The Scroll Marked I,  Form good habits and become their slavesThe Scroll Marked II,  Show love and compassion to the world and you shall find it returnedThe Scroll Marked III, Persistence will bring you successThe Scroll Marked IV, Love yourselfThe Scroll Marked V, Seize the dayThe Scroll Marked VI, Do not fall victim to fear and disappointmentThe Scroll Marked VII, Do not take life too seriouslyThe Scroll Marked VIII, Find ways to create value for othersThe Scroll Marked IX, Act decisively, do not procrastinateThe Scroll Marked X, Pray for guidanceEach is to be read 3 times a day, once of these times out loud, for 30 days a piece.  After this year of renewal, anyone following this process faithfully will not be able to but have a much better outlook on life and themselves.\", 'Shad Helmstetter has been in the forefront of autosuggestion and positive mental attitude thinking for the last 40 years.  The approaches used by Dr. Helmstetter in the book are not new or revolutionary in the sense that they have been the foundation for writers like Napoleon Hill, Dale Carnegie and Clement Stone for well over a century.  They are, however, effective and in this book, very well described and clearly articulated.The topic is not as controversial as some might make it out to be.  The subconscious mind has powerful influences on our actions and reactions.  The ability to influence the subconscious can, in part, be affected by using many of the techniques described in the book - which will impact attitude and behavior.A worthy read - and while only useful if put into practice - a good primer for changing your self-talk and your behaviors.', 'Joanna Barsh, a 30 year veteran of McKinsey, takes the reader on a journey through self paced and extremely insightful exercises to arrive at a better place for leadership and self awareness in this easy to read but challenging book.  Barsh begins by focusing on the element of centering.  Centering crossed my path as &#34;centering prayer&#34; several years ago, and revolves around self awareness, stillness and connection as well as grounding.  Barsh crosswalks this meditative practice to an active implementation in &#34;Centered Leadership&#34;.The book begins with a useful introduction to centered leadership, and an introduction to the five components which make up the centered leadership facets:* Framing - self awareness, pausing and adaptability* Connecting - Trust relationships, networks and community, sponsorships* Engaging - Presence, ownership and taking risks and action* Energizing - Energy balance, recovery and sustaining practices* Meaning - Happiness, core strengths and purposeBarsh then walks the reader through each of the five elements, accompanied by a series of self reflective and team exercised designed to awaken and develop each of the five facets.  At the end, she hopes that he reader will have improved their leadership impact, self-fulfillment and resilience.Ultimately, the book is a useful tool - as much for self awareness and self development as to provide enlightening leadership techniques.  Barth seems to embrace the approach that to lead, one must first take care of themselves and understand (perhaps even &#34;center&#34;) themselves for maximum effectiveness.  It is a worthwhile read, and the exercises are thought provoking and useful.', \"If you are a fan of the E-Myth books, this one is far superior. As the CEO of a PE backed company, and having done this type of deal several times over the last 20 years, this book is spot on.  The &#34;Ted Tips&#34; and action plan in the book WILL WORK, and are critical to the small-mid size business owner.  There's a real need to be able to understand the exit when you enter a business, and most of us forget that.  This book is easy to read, entertaining, practical, straightforward and accurate in assessment and scope.  If you read one business book this year, business owners, it should be this one.  6 stars....\", \"I purchased the audio set and found Eric Worre to be exceptionally inspiring, powerful and practical.  I am not in MLM, but do own my own business, and tend to listen to these types of programs to provide both motivation and ideas for my business.  This program is one of the best out there.  You will not go wrong in picking up the CD's, and I would expect the book to be exceptional as well.\", \"As a 20 year veteran of business, including C-Level roles for over a decade, this book hits home on the psychology of leadership.  Actionable and easy to understand, Cramer's book captures the fundamental truths in leadership and self-development - managing and emphasizing the strengths and the positives.  Discussing such actionable items as the 5:1 ratio of positive to negative comments, and the paradigm of See, Say, Do, Cramer brings a positive and psychologically solid approach to leadership that is only beginning to emerge elsewhere in the study of the discipline.The book itself is easy to read, and filled with both actionable steps and questions.  Supporting the steps and questions are numerous entertaining anecdotes and examples - supported in many cases with statistics and studies.  The book was entertaining and enlightening enough that I read it in a 24 hour period - a rare feat for a book of this type.  Worth picking up and reading for anyone - not just appointed &#34;leaders&#34;.  You will learn a lot about yourself and those around you by reading the book and following the lessons.\", \"This book covers the landscape - and does it extremely well.  Written by a veteran of start up challenges, Derek Lidow takes the reader through a well written series of anecdotes and antidotes to prescribe a few key elements for leadership in any organization.  Discussing the business in terms of maturity stage (he outlines 4), critical skill sets (he discusses 5), as well as strategy development and crisis management, Lidow truly captures the essence of leadership challenges and approaches for the entrepreneurial leader.My own experiences in early stage organizations reinforce my belief that if you are an entrepreneur, this book needs to be on your short list to read - right along with &#34;Lean Start Up&#34; and &#34;Thriving on Chaos&#34;.  The only gripe I had was that his major points weren't well summarized in the chapter.  Imagine my delight when the appendices (READ THEM) were concise and cogent summaries of his major leadership elements.As it says on the cover, and I agree, &#34;An instant classic.&#34;\", \"This is perhaps the best book I've read yet for introducing big data concepts, strategies, terms and technologies to the non-technologist.  Written for the business leader or general practitioner, Davenport takes the reader through an easily digested 200 pages of introduction to understanding what big data is, why it is important to you, how to look at the strategy, people and technology, and some of the challenges and rewards of a comprehensive big data strategy - including an emphasis on the evolving world of analytics in a big data enabled environment.As a business leader in the midst of a shift to broader use of big data tools and infrastructure, this book proved to be an excellent resource for getting up to speed on major issues and understanding some of the questions to ask and issues to look out for.  A good adder to any manager's bookshelf.\", \"If you buy the book and follow the relatively simple to understand rules that Dr. Agus lays out, you will be healthier, feel better and be able to understand your body and your mind better than 90% of the population.  Agus takes some relatively hard and controversial positions on supplements, GMO's, airport screening and frozen foods that may not resonate with all readers - especially those that Agus tends to target.Having said that, the principles are straightforward and easy to understand, they largely make sense, and many of the 1 star reviews here are so hyper focused on the GMO issue that they ignore that the rest of the book has a lot of good, useful and practical information for the reader that will help most people who buy and read this book.  It isn't flashy, it doesn't dive deep into the science behind the assertions, and it has some &#34;pop culture&#34; feel.  However, it is a good and useful book - one that will improve awareness and health - and that alone is worth picking it up and reading it.\", \"I admit that the opening paragraphs reminded me of Tim Ferriss and I thought I was going to get the abridged edition of the 4 Hour Work Week.  And, candidly, there's a good bot of that here. The book is an entertaining and inspiring view of the mirror and the steps to take to change the image.  Altucher pulls no punches, and provides insights and humorous as well as heart wrenching stories of his own successes and failures.  The need to exercise the body, mind and soul - and the way in which he provides methods and suggestions - makes the read practical as well as inspirational.  The writing style is conversational and easy, and you feel kindred as if the man in the mirror is known by the author -- and is truly everyman,The Daily Practice and the equation of improvement to flossing teeth are humorous truisms and useful perspectives.  The practical list making, idea generating and self-publishing tips are immediately applicable.  Bottom line is this is a great, quick, and potentially life impacting read.\"]\n",
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14057/14057 [00:00<00:00, 1087489.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total items : 25082\n",
      "11307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## filter items\n",
    "import random\n",
    "def filter_func(raw_datas):\n",
    "    filtered_datas = []\n",
    "    for data in tqdm(raw_datas):\n",
    "        if data[\"user\"] and data[\"item\"] and data[\"rating\"] and data[\"ReviewTime\"] and data[\"reviewText\"] and data[\"title\"] and item_count[data[\"item\"]] >= 10:\n",
    "            filtered_datas.append(data)\n",
    "    return filtered_datas\n",
    "\n",
    "filtered_datas = filter_func(res)\n",
    "print(\"after filtered items total datas: \",len(filtered_datas))\n",
    "\n",
    "## filter users interactions length less than 20\n",
    "def filter_users(raw_datas):\n",
    "    filtered_datas = []\n",
    "    for data in tqdm(raw_datas):\n",
    "        if user_count[data[\"user\"]] >=20 : \n",
    "            filtered_datas.append(data)\n",
    "    return filtered_datas\n",
    "filtered_datas_2 = filter_users(filtered_datas)\n",
    "print(\"after filter users totla datas: \", len(filtered_datas_2))\n",
    "\n",
    "\n",
    "\n",
    "user_total = set()\n",
    "item_total = set()\n",
    "for data in tqdm(filtered_datas_2):\n",
    "    user_total.add(data[\"user\"])\n",
    "    item_total.add(data[\"item\"])\n",
    "print(\"total user: \", len(user_total))\n",
    "print(\"total items: \", len(item_total))\n",
    "\n",
    "### 对user item 进行编码\n",
    "user_2_id = {}\n",
    "item_2_id = {}\n",
    "for data in tqdm(filtered_datas_2):\n",
    "    user = data[\"user\"]\n",
    "    item = data[\"item\"]\n",
    "    user_2_id[user] = user_2_id.get(user,len(user_2_id)+1) \n",
    "    item_2_id[item] = item_2_id.get(item,len(item_2_id)+1)\n",
    "\n",
    "user_sequences_id = {}\n",
    "user_sequences_title = {}\n",
    "user_rating = {}\n",
    "user_reviews = {}\n",
    "null_review = 0\n",
    "for data in tqdm(filtered_datas_2):\n",
    "    user = user_2_id[data[\"user\"]]\n",
    "    item = data[\"item\"]\n",
    "    rating = data[\"rating\"]\n",
    "    title = data[\"title\"]\n",
    "    reviewtext = data[\"reviewText\"]\n",
    "    user_sequences_id[user] = user_sequences_id.get(user,[user]) + [item_2_id[item]]\n",
    "    user_sequences_title[user] = user_sequences_title.get(user,[]) + [title]\n",
    "    user_rating[user] = user_rating.get(user,[]) + [rating]\n",
    "    user_reviews[user] = user_reviews.get(user, [])\n",
    "    user_reviews[user].append(reviewtext)\n",
    "print(user_sequences_id[1])\n",
    "print(user_sequences_title[1])\n",
    "print(user_rating[1])\n",
    "print(user_reviews[1])\n",
    "print(len(user_reviews[1]))\n",
    "### check data \n",
    "for data in tqdm(user_sequences_id):\n",
    "    # print(len(user_sequences_id[data][1:]), len(user_sequences_title[data]),len(user_rating[data]), len(user_reviews[user]))\n",
    "    assert len(user_sequences_id[data][1:]) == len(user_sequences_title[data]) == len(user_rating[data]) == len(user_reviews[data])\n",
    "\n",
    "\n",
    "id_2_title = {}\n",
    "count = 0\n",
    "for user in user_sequences_id:\n",
    "    items_id = user_sequences_id[user][1:]\n",
    "    if len(items_id) > 11:\n",
    "        count += 1\n",
    "    items_title = user_sequences_title[user]\n",
    "    length = len(items_id)\n",
    "    for i in range(length):\n",
    "        id_2_title[items_id[i]] = items_title[i]\n",
    "print(\"total items :\", len(id_2_title))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter cold users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1349\n"
     ]
    }
   ],
   "source": [
    "cold_users = []\n",
    "for user in user_sequences_id:\n",
    "    if len(user_sequences_id[user]) <=6 :\n",
    "        cold_users.append(user)\n",
    "print(len(cold_users))\n",
    "cold_users_dict = {\"cold_users_id\":cold_users}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(file, data):\n",
    "    with open(file, \"w\") as f:\n",
    "        json.dump(data, f)\n",
    "save_json(\"../data/books_v2/user_sequences_id.json\", user_sequences_id)\n",
    "save_json(\"../data/books_v2/user_sequences_title.json\", user_sequences_title)\n",
    "save_json(\"../data/books_v2/user_rating.json\", user_rating)\n",
    "save_json('../data/books_v2/user_review.json',user_reviews)\n",
    "save_json('../data/books_v2/cold_users.json',cold_users_dict)\n",
    "save_json('../data/books_v2/id_2_title.json', id_2_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CKF dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/books_v2/user_sequences_id.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 318\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;66;03m# with jsonlines.open('../data/books_for_train/train.jsonl', 'w') as writer:\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;66;03m#     writer.write_all(train_data)\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \n\u001b[1;32m    313\u001b[0m \n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# with jsonlines.open('../data/books_for_train/test.jsonl', 'w') as writer:\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m#     writer.write_all(test_data)\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 318\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 255\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():   \n\u001b[0;32m--> 255\u001b[0m     id_2_title, all_item_id, user_title_sequences,user_id_sequences, user_rating_sequences, user_review_sequences \u001b[38;5;241m=\u001b[39m \u001b[43mdata_process\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/books_v2/user_sequences_title.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/books_v2/user_sequences_id.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/books_v2/user_rating.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/books_v2/user_review.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m     ctr_train_data, ctr_test_data ,sequential_train_data, sequential_test_data, rating_train_data, rating_test_data, exp_train_data, exp_test_data, cold_users \u001b[38;5;241m=\u001b[39m generate_data(id_2_title, all_item_id, user_title_sequences, user_id_sequences, user_rating_sequences, user_review_sequences)\n\u001b[1;32m    257\u001b[0m     ctr_train \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[1], line 52\u001b[0m, in \u001b[0;36mdata_process\u001b[0;34m(user_sequeneces_title, user_sequences_id, user_sequences_rating, user_sequences_review)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata_process\u001b[39m(user_sequeneces_title:\u001b[38;5;28mstr\u001b[39m, user_sequences_id:\u001b[38;5;28mstr\u001b[39m, user_sequences_rating:\u001b[38;5;28mstr\u001b[39m, user_sequences_review:\u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     51\u001b[0m     user_title_sequences \u001b[38;5;241m=\u001b[39m load_json(user_sequeneces_title)\n\u001b[0;32m---> 52\u001b[0m     user_id_sequences \u001b[38;5;241m=\u001b[39m \u001b[43mload_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_sequences_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     user_sequences_rating \u001b[38;5;241m=\u001b[39m load_json(user_sequences_rating)\n\u001b[1;32m     54\u001b[0m     user_sequences_review \u001b[38;5;241m=\u001b[39m load_json(user_sequences_review)\n",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m, in \u001b[0;36mload_json\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_json\u001b[39m(file_path:\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39mDict:\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     15\u001b[0m         data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/books_v2/user_sequences_id.json'"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "import json \n",
    "from typing import Dict, List\n",
    "import random \n",
    "import numpy as np\n",
    "from torch import exp_, rand\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "def load_json(file_path:str)->Dict:\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def generate_sequential_recommend_prompt(data):\n",
    "\n",
    "    \n",
    "    prompt = f\"\"\"The user's preferences are encoded in <unk>, he has interacted with the following items:{data[\"history_list\"]} recently.\n",
    "    Based on this information, I want you to select the user's favorite item in the list of candidate items following: {data[\"candidate_item_title\"]}. Your response should be a item's title in the list of candidate items.\n",
    "\"\"\"\n",
    "    return {\"input\":prompt, 'output': data['output'], \"user_id\":data['user_id'], \"candidate_item\":data[\"candidate_item\"], \"task_type\":\"sequential\", \"history_items_id\":data[\"history_items_id\"]}\n",
    "\n",
    "def generate_ctr_prompt(data):\n",
    "\n",
    "    prompt = f\"\"\"The user's preferences are encoded in <unk> , additionally, he has recently interacted the following items he likes {data[\"history_list\"]}.\n",
    "    Based on the user's preferences and items he liked, I want you to determine if the user will like the item whose title is: \"{data[\"candidate_item_title\"]} and its encoded feature is <unk>.\". Your response should be a simple \"Yes\" or \"No\" without any explanations.\n",
    "\"\"\"\n",
    "    return {\"input\":prompt, 'output': data['output'], \"user_id\":data['user_id'], \"candidate_item\":data[\"candidate_item\"], \"task_type\":\"ctr\", \"history_items_id\":data[\"history_items_id\"]}\n",
    "\n",
    "def generate_rating_prompt(data):\n",
    "\n",
    "    prompt = f\"\"\"The user whose preferences is <unk>  rated the following items he has interacted: {data[\"history_list\"]}. \n",
    "    Based on the user's rating, now given your item: {data[\"candidate_item_title\"]} with encoded feature is <unk>, you need to predict how will user rate for this item.Your response should be a number between 1-5 where 1 being lowest and 5 being highest.\n",
    "\"\"\"\n",
    "    return {\"input\":prompt, \"output\":data[\"output\"], \"user_id\":data[\"user_id\"], \"candidate_item\":data[\"candidate_item\"], \"task_type\":\"rating\", \"history_items_id\":data[\"history_items_id\"]}\n",
    "\n",
    "def generate_exp_prompt(data):\n",
    "\n",
    "    ### rating --> review \n",
    "    prompt = f\"\"\"Now, a user whose feature is <unk>'s comment on item {data[\"candidate_item_title\"]} whose encoded feature is <unk>, the comment content is as follows:\n",
    "    {data[\"history_list\"]}. Based on user information and review content, how do you think the user would rate the item? Your response should be a number between 1-5 where 1 being lowest and 5 being highest.\n",
    "\"\"\"\n",
    "    return {\"input\":prompt, \"output\":data[\"output\"], \"user_id\":data[\"user_id\"], \"candidate_item\":data[\"candidate_item\"], \"task_type\":\"exp\", \"history_items_id\":data[\"history_items_id\"]}\n",
    "\n",
    "def data_process(user_sequeneces_title:str, user_sequences_id:str, user_sequences_rating:str, user_sequences_review:str):\n",
    "\n",
    "    user_title_sequences = load_json(user_sequeneces_title)\n",
    "    user_id_sequences = load_json(user_sequences_id)\n",
    "    user_sequences_rating = load_json(user_sequences_rating)\n",
    "    user_sequences_review = load_json(user_sequences_review)\n",
    "    id_2_title = load_json(\"../data/books_v2/id_2_title.json\")\n",
    "    all_item_id = set()\n",
    "    for user in user_title_sequences:\n",
    "        item_ids = user_id_sequences[user][1:]\n",
    "        item_titles = user_title_sequences[user]\n",
    "       \n",
    "        assert len(item_ids) == len(item_titles)\n",
    "\n",
    "        for id in item_ids:\n",
    "            \n",
    "            all_item_id.add(id)\n",
    "\n",
    "    return id_2_title, all_item_id, user_title_sequences, user_id_sequences, user_sequences_rating, user_sequences_review\n",
    "\n",
    "def generate_data(id_2_title, all_item_id, user_title_sequences,user_id_sequences, user_sequences_rating, user_sequences_review):\n",
    "\n",
    "    ctr_train_data = []\n",
    "    ctr_test_data = []\n",
    "    sequential_train_data = []\n",
    "    sequential_test_data = []\n",
    "    rating_train_data = []\n",
    "    rating_test_data = []\n",
    "    exp_train_data = []\n",
    "    exp_test_data = []\n",
    "    users_recode= load_json('../data/books_v2/cold_users.json')\n",
    "    cold_users = users_recode[\"cold_users_id\"]\n",
    "    print(\"cold_users:\", len(cold_users))\n",
    "    \n",
    "    # user_list = list(user_id_sequences.keys())\n",
    "    \n",
    "    # random.shuffle(user_list)\n",
    "    # train_user_ratio = 1\n",
    "    # train_user_id_sequences = user_list[:int(train_user_ratio * len(user_list))]    \n",
    "    \n",
    "    for user in tqdm(user_id_sequences,desc=\"generate train data\"):\n",
    "        if int(user) in cold_users : continue\n",
    "        user_id = (user_id_sequences[user][0])\n",
    "        former_info = \"\"\n",
    "        extra_info = \"\"\n",
    "        for i in range(2):\n",
    "            #### ctr data \n",
    "            tmp = {}\n",
    "            tmp[\"user_id\"] = user_id\n",
    "            try:\n",
    "                start_pos = random.randint(0,3)\n",
    "                end_pos = random.randint(start_pos+4, len(user_id_sequences[user][1:-2]))\n",
    "            except:\n",
    "                start_pos = 0\n",
    "                end_pos = -2\n",
    "            # item_list = user_id_sequences[user][1:15][:-1]    ### 最后一个商品是测试集\n",
    "            # sample_number = random.randint(4,len(item_list)-3)\n",
    "            try:\n",
    "                history_list , candidate_item_id = user_id_sequences[user][1:][start_pos:end_pos][:10][:-1], user_id_sequences[user][1:][start_pos:end_pos][:10][-1]   ### 确保历史长度不超过10\n",
    "            except:\n",
    "                print(user_id_sequences[user][1:][start_pos:end_pos][:10])\n",
    "                raise\n",
    "            if random.random() < 0.5:\n",
    "                tmp[\"output\"] = \"Yes.\"\n",
    "            else:\n",
    "                candidate_item_id = random.sample(all_item_id,1)[0]\n",
    "                tmp[\"output\"] = \"No.\"\n",
    "            \n",
    "            tmp[\"history_list\"] = [former_info + id_2_title[str(item)] + extra_info for item in history_list]\n",
    "            tmp[\"history_items_id\"] = history_list\n",
    "            tmp[\"candidate_item_title\"] = id_2_title[str(candidate_item_id)]\n",
    "            tmp[\"candidate_item\"] = [candidate_item_id] + [0] * 9\n",
    "            ctr_train_data.append(tmp)\n",
    "            \n",
    "            #### TopK\n",
    "            if i >= 0:\n",
    "                tmp_seq = deepcopy(tmp)\n",
    "                try:\n",
    "                    start_pos = random.randint(0,3)\n",
    "                    end_pos = random.randint(start_pos+4, len(user_id_sequences[user][1:-2]))\n",
    "                except:\n",
    "                    start_pos = 0\n",
    "                    end_pos = -2\n",
    "                history_list_sequences = user_id_sequences[user][1:][start_pos:end_pos][:10]   ### 确保历史长度不超过10\n",
    "                history_list , target_item = history_list_sequences[:-1], history_list_sequences[-1]        \n",
    "                tmp_seq[\"history_items_id\"] = history_list\n",
    "                tmp_seq[\"history_list\"] = [former_info + id_2_title[str(item)] + extra_info for item in history_list]\n",
    "                candidate_id_list = random.sample(all_item_id, 9)\n",
    "                candidate_id_list += [target_item]\n",
    "\n",
    "                random.shuffle(candidate_id_list)\n",
    "\n",
    "                candidate_title_list = [ \"item title: \" + id_2_title[str(item)] + \", and its encoded feature is <unk>\" for item in candidate_id_list]\n",
    "                tmp_seq[\"candidate_item_title\"] = candidate_title_list\n",
    "                tmp_seq[\"candidate_item\"] = candidate_id_list\n",
    "                tmp_seq[\"output\"] = id_2_title[str(target_item)]\n",
    "                sequential_train_data.append(tmp_seq)\n",
    "\n",
    "            #### rating predict\n",
    "            if i >= 1:\n",
    "                tmp_rating = deepcopy(tmp)\n",
    "                try:\n",
    "                    start_pos = random.randint(0,3)\n",
    "                    end_pos = random.randint(start_pos+4, len(user_id_sequences[user][1:-2]))\n",
    "                except:\n",
    "                    start_pos = 0\n",
    "                    end_pos = -2\n",
    "                target_item_id = user_id_sequences[user][1:][start_pos:end_pos][:10][-1]\n",
    "                history_list_title = user_title_sequences[user][start_pos:end_pos][:10][:-1]\n",
    "                history_list_rating = user_sequences_rating[user][start_pos:end_pos][:10][:-1]\n",
    "                history_list = [former_info + item_title + extra_info + \", rating: \" + str(item_rate) for item_title, item_rate in zip(history_list_title,history_list_rating)]\n",
    "                tmp_rating[\"history_list\"]=history_list\n",
    "                tmp_rating[\"candidate_item\"] = [target_item_id] + [0] * 9\n",
    "                tmp_rating[\"history_items_id\"] = user_id_sequences[user][1:][start_pos:end_pos][:10][:-1]\n",
    "                tmp_rating[\"candidate_item_title\"] = id_2_title[str(target_item_id)]\n",
    "                tmp_rating[\"output\"] = user_sequences_rating[user][start_pos:end_pos][:10][-1]\n",
    "                rating_train_data.append(tmp_rating)\n",
    "            ### exp\n",
    "            if i>=1:\n",
    "                tmp_exp = deepcopy(tmp)\n",
    "                item_index = random.randint(0, len(user_id_sequences[user][1:])-3)\n",
    "                rating = user_sequences_rating[user][item_index]\n",
    "                item_title = user_title_sequences[user][item_index]\n",
    "                review = \" \".join(user_sequences_review[user][item_index].split(\" \")[:100])\n",
    "                tmp_exp[\"history_list\"] = review\n",
    "                tmp_exp[\"candidate_item_title\"] = item_title\n",
    "                tmp_exp[\"candidate_item\"] = [user_id_sequences[user][1:][item_index]] + [0] * 9\n",
    "                tmp_exp[\"history_items_id\"] = [user_id_sequences[user][1:][item_index]]\n",
    "                tmp_exp[\"output\"] = rating\n",
    "                exp_train_data.append(tmp_exp)\n",
    "\n",
    "    \n",
    "    for user in tqdm(user_id_sequences,desc=\"generate test data\"): \n",
    "        \n",
    "        test_tmp_ctr, test_tmp_seq, test_tmp_rating, test_tmp_exp = {}, {}, {}, {}\n",
    "        test_ctr_each_user_data = []\n",
    "        dic1 = {1:test_ctr_each_user_data, 2:test_tmp_seq, 3:test_tmp_rating, 4:test_tmp_exp}\n",
    "        dic2 = {1:ctr_test_data, 2:sequential_test_data, 3:rating_test_data, 4:exp_test_data}\n",
    "        flag = 0\n",
    "        \n",
    "        user_id = user_id_sequences[user][0]\n",
    "        test_tmp_ctr[\"user_id\"] = user_id\n",
    "        test_history_length = random.randint(7,11)\n",
    "        history_list = user_id_sequences[user][1:][-test_history_length:-1]\n",
    "        test_rating_sequences = user_sequences_rating[user][-test_history_length:-1]\n",
    "        test_title_sequences = user_title_sequences[user][-test_history_length:-1]\n",
    "        test_tmp_ctr[\"history_items_id\"] = history_list\n",
    "        test_tmp_ctr[\"history_list\"] =  [former_info + id_2_title[str(item)] + extra_info for item in history_list]\n",
    "        for i in range(4):\n",
    "            test_tmp_ctr_copy = deepcopy(test_tmp_ctr)\n",
    "            if random.random() < 0.5:\n",
    "                if flag == 1:continue\n",
    "                candidate_item_id = user_id_sequences[user][-1]\n",
    "                test_tmp_ctr_copy[\"output\"] = \"Yes.\"\n",
    "                flag = 1\n",
    "            else:\n",
    "                candidate_item_id = random.sample(all_item_id,1)[0]\n",
    "                test_tmp_ctr_copy[\"output\"] = \"No.\"\n",
    "            \n",
    "            test_tmp_ctr_copy[\"candidate_item\"] = [candidate_item_id] + [0] * 9\n",
    "            test_tmp_ctr_copy[\"candidate_item_title\"] = id_2_title[str(candidate_item_id)]\n",
    "\n",
    "            test_ctr_each_user_data.append(test_tmp_ctr_copy)\n",
    "        # ctr_test_data.append(test_tmp_ctr)\n",
    "        \n",
    "        \n",
    "        \n",
    "        test_tmp_seq[\"user_id\"] = user_id\n",
    "        test_tmp_seq[\"history_list\"] = [former_info + id_2_title[str(item)] + extra_info for item in history_list]\n",
    "        test_tmp_seq[\"history_items_id\"] = history_list\n",
    "        candidate_id_list = random.sample(all_item_id, 9)\n",
    "        candidate_id_list += [user_id_sequences[user][-1]]\n",
    "        random.shuffle(candidate_id_list)\n",
    "        candidate_title_list = [\"item title: \" + id_2_title[str(item)] + \", and its encoded feature is <unk>\"  for item in candidate_id_list]\n",
    "        test_tmp_seq[\"candidate_item_title\"] = candidate_title_list\n",
    "        test_tmp_seq[\"candidate_item\"] = candidate_id_list\n",
    "        test_tmp_seq[\"output\"] = id_2_title[str(user_id_sequences[user][-1])]\n",
    "        # sequential_test_data.append(test_tmp_seq)\n",
    "        \n",
    "\n",
    "       \n",
    "        test_tmp_rating[\"user_id\"] = user_id\n",
    "        test_tmp_rating[\"history_list\"] = [former_info + item_title + extra_info + \", rating: \" + str(item_rate) for item_title, item_rate in zip(test_title_sequences, test_rating_sequences)]\n",
    "        test_tmp_rating[\"candidate_item_title\"] = user_title_sequences[user][-1]\n",
    "        test_tmp_rating[\"history_items_id\"] = history_list\n",
    "        test_tmp_rating[\"candidate_item\"] = [user_id_sequences[user][-1]] + [0] * 9\n",
    "        test_tmp_rating[\"output\"] = user_sequences_rating[user][-1]\n",
    "        # rating_test_data.append(test_tmp_rating)\n",
    "\n",
    "        \n",
    "        test_tmp_exp[\"user_id\"] = user_id\n",
    "        test_tmp_exp[\"history_list\"] = \" \".join(user_sequences_review[user][-1].split(\" \")[:100]) ### limit 100 words\n",
    "        test_tmp_exp[\"candidate_item_title\"] = user_title_sequences[user][-1]\n",
    "        test_tmp_exp[\"candidate_item\"] = [user_id_sequences[user][-1]] + [0] * 9\n",
    "        test_tmp_exp[\"history_items_id\"] = [user_id_sequences[user][-1]]\n",
    "        test_tmp_exp[\"output\"] = user_sequences_rating[user][-1]\n",
    "        # exp_test_data.append(test_tmp_exp)\n",
    "        seed = random.randint(1,4)\n",
    "        if seed == 1:\n",
    "            dic2[seed].extend(test_ctr_each_user_data)\n",
    "        else:\n",
    "            dic2[seed].append(dic1[seed])\n",
    "\n",
    "    return ctr_train_data, ctr_test_data, sequential_train_data, sequential_test_data, rating_train_data, rating_test_data, exp_train_data, exp_test_data , cold_users\n",
    "                        \n",
    "def main():   \n",
    "    id_2_title, all_item_id, user_title_sequences,user_id_sequences, user_rating_sequences, user_review_sequences = data_process('../data/books_v2/user_sequences_title.json', '../data/books_v2/user_sequences_id.json', '../data/books_v2/user_rating.json', '../data/books_v2/user_review.json')\n",
    "    ctr_train_data, ctr_test_data ,sequential_train_data, sequential_test_data, rating_train_data, rating_test_data, exp_train_data, exp_test_data, cold_users = generate_data(id_2_title, all_item_id, user_title_sequences, user_id_sequences, user_rating_sequences, user_review_sequences)\n",
    "    ctr_train = []\n",
    "    ctr_test = []\n",
    "    sequential_train = []\n",
    "    sequential_test = []\n",
    "    rating_train = []\n",
    "    rating_test = []\n",
    "    exp_train = []\n",
    "    exp_test = []\n",
    "\n",
    "    for data in (ctr_train_data):\n",
    "        ctr_train.append(generate_ctr_prompt(data))\n",
    "    for data in ctr_test_data:\n",
    "        ctr_test.append(generate_ctr_prompt(data))\n",
    "    random.shuffle(rating_train)\n",
    "    print(\"ctr train data length: \", len(ctr_train))\n",
    "\n",
    "\n",
    "    for data in sequential_train_data:\n",
    "        sequential_train.append(generate_sequential_recommend_prompt(data))\n",
    "    print(\"sequential train data length: \", len(sequential_train))\n",
    "    for data in sequential_test_data:\n",
    "        sequential_test.append(generate_sequential_recommend_prompt(data))\n",
    "\n",
    "\n",
    "    for data in rating_train_data:\n",
    "        rating_train.append(generate_rating_prompt(data))\n",
    "    print(\"rating data length: \", len(rating_train))\n",
    "    for data in rating_test_data:\n",
    "        rating_test.append(generate_rating_prompt(data))\n",
    "\n",
    "    for data in exp_train_data:\n",
    "        exp_train.append(generate_exp_prompt(data))\n",
    "    print(\"exp data length: \", len(exp_train))\n",
    "    for data in exp_test_data:\n",
    "        exp_test.append(generate_exp_prompt(data))\n",
    "    print(\"total cold users: \", len(cold_users))\n",
    "    warm_user_datas , cold_user_datas = [] , []\n",
    "    for datas in tqdm([ctr_test, sequential_test, rating_test, exp_test]):\n",
    "        for data in tqdm(datas):\n",
    "            if data[\"user_id\"] in cold_users:\n",
    "                cold_user_datas.append(data)\n",
    "            else:\n",
    "                warm_user_datas.append(data)\n",
    "    print(len(warm_user_datas))\n",
    "    print(len(cold_user_datas))\n",
    "    train_data = ctr_train + sequential_train + rating_train + exp_train\n",
    "    random.shuffle(train_data)\n",
    "    print(\"train data length: \", len(train_data))\n",
    "    \n",
    "    test_data = warm_user_datas + cold_user_datas\n",
    "    print(\"test_data length: \", len(test_data))\n",
    "    random.shuffle(test_data)\n",
    "    print(test_data[100])\n",
    "    # with jsonlines.open('../data/books_for_train/train.jsonl', 'w') as writer:\n",
    "    #     writer.write_all(train_data)\n",
    "\n",
    "\n",
    "    # with jsonlines.open('../data/books_for_train/test.jsonl', 'w') as writer:\n",
    "    #     writer.write_all(test_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
